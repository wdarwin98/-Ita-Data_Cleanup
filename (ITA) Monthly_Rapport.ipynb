{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875864dc",
   "metadata": {},
   "source": [
    "**Consolidated Monthly Rapport**\n",
    "- This code generates the Monthly Rapport.\n",
    "- To generate the desired outcome please follow the instructions as listed in each cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24494ca",
   "metadata": {},
   "source": [
    "Prerequisite: Install the following libraries if you have not done so.\n",
    "Required libraries include - pandas and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aecda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yzmq (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yzmq (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yzmq (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yzmq (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yzmq (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yzmq (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: c:\\programdata\\anaconda3\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.21.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yzmq (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yzmq (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yzmq (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yzmq (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yzmq (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yzmq (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: c:\\programdata\\anaconda3\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Prerequisite libraries to install before running\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b97c680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661d87ac",
   "metadata": {},
   "source": [
    "Instruction #1 : Copy and Paste file path to their appropriate destinations.\n",
    "Instruction #2 : Once finished, click Run All."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b9d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path for Shipments Out (Edit: Needs to filter by Shipping Address \"**\")\n",
    "# Replace the path with the actual path to your Shipments Consolidated file\n",
    "shipments = pd.read_excel(r\"C:\\Users\\Red & White ASUS\\Documents\\(ITA) Data Cleanup and Transformation\\Raw Data - 1st Oct 2025\\Afsendte202509.xlsx\")\n",
    "\n",
    "# Define the file path for Goods In\n",
    "# Replace the path with the actual path to your Inbound Orderline file\n",
    "inbound = pd.read_excel(r\"C:\\Users\\Red & White ASUS\\Documents\\(ITA) Data Cleanup and Transformation\\Raw Data - 1st Oct 2025\\2025-09-30T03_20_09_230_inboundOrderLine.xlsx\")\n",
    "\n",
    "# Define the file path for Moved to Production (Edit: Take from Shipments file - filter by Shipping Address \"Production Order\")\n",
    "# Replace the path with the actual path to your Production file\n",
    "production = pd.read_excel(r\"C:\\Users\\Red & White ASUS\\Documents\\(ITA) Data Cleanup and Transformation\\Raw Data - 1st Oct 2025\\Afsendte202509.xlsx\")\n",
    "\n",
    "# Define the file path for Inbound from Production (Edit: Take from SKUs that have C/R from the Inbound Orderline file)\n",
    "# Replace the path with the actual path to your Inbound from Production file\n",
    "inbound_prod = pd.read_excel(r\"C:\\Users\\Red & White ASUS\\Documents\\(ITA) Data Cleanup and Transformation\\Raw Data - 1st Oct 2025\\2025-09-30T03_20_09_230_inboundOrderLine.xlsx\")\n",
    "\n",
    "# Define the file path for Inventory Ultimo\n",
    "# Replace the path with the actual path to your Inventory Consolidated file\n",
    "inventory_dk = pd.read_excel(r\"C:\\Users\\Red & White ASUS\\Documents\\(ITA) Data Cleanup and Transformation\\Raw Data - 1st Oct 2025\\DK-END OF MONTH INVENTORY REPORT (Stilling) - September.xlsx\", skiprows=1, usecols=\"A:F\")\n",
    "inventory_de = pd.read_excel(r\"C:\\Users\\Red & White ASUS\\Documents\\(ITA) Data Cleanup and Transformation\\Raw Data - 1st Oct 2025\\DE-MONTH END INVENTORY REPORT - 09_25.xlsx\", skiprows = 2)\n",
    "\n",
    "# Define the file path for Current Primo\n",
    "# Replace the path with the actual path to your previous month's DK Rapport file\n",
    "previous_rapport_DK = pd.read_excel(r\"C:\\Users\\USER\\OneDrive\\Documents\\House of Analytics\\ITA\\Raw Data - 1st Oct 2025\\Final Rapport Aug 2025 (Adjusted).xlsx\", sheet_name=\"DK\")\n",
    "# Replace the path with the actual path to your previous month's DE Rapport file\n",
    "previous_rapport_DE = pd.read_excel(r\"C:\\Users\\USER\\OneDrive\\Documents\\House of Analytics\\ITA\\Raw Data - 1st Oct 2025\\Final Rapport Aug 2025 (Adjusted).xlsx\", sheet_name=\"DE\")\n",
    "# Replace the path with the actual path to your previous month's DE Rapport file\n",
    "previous_rapport_TOT = pd.read_excel(r\"C:\\Users\\USER\\OneDrive\\Documents\\House of Analytics\\ITA\\Raw Data - 1st Oct 2025\\Final Rapport Aug 2025 (Adjusted).xlsx\", sheet_name=\"TOT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dde3d7",
   "metadata": {},
   "source": [
    "Data Transformation - Aggregations: Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea94d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cleanup files\n",
    "# # Cleanup the Inventory files\n",
    "# inventory_skandflen['Område'] = np.where(inventory_skandflen['Område'].isin(['S2', 'S4']), 'DK', np.where(inventory_skandflen['Område'] == 'F1', 'DE', inventory_skandflen['Område']))\n",
    "\n",
    "# # Aggregate the total Mængde per Varenummer and Område\n",
    "# inventory_skandflen_grouped = inventory_skandflen.groupby(['Varenummer', 'Område'], as_index=False)['Mængde'].sum()\n",
    "\n",
    "# # Remove #FP from Varenummer in inventory_skandflen_grouped\n",
    "# inventory_skandflen_grouped['Varenummer'] = inventory_skandflen_grouped['Varenummer'].str.replace('#FP', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d058f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Aggregate the total On Hand per SKU and Område from Handewitt\n",
    "# inventory_handewitt['Område'] = 'DE'\n",
    "# inventory_handewitt_grouped = inventory_handewitt.groupby(['SKU', 'Område'], as_index=False)['On Hand'].sum()\n",
    "# inventory_handewitt_grouped.rename(columns={'SKU': 'Varenummer', 'On Hand': 'Mængde'}, inplace=True)\n",
    "# inventory_handewitt_grouped.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6a15a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rename columns for merging\n",
    "# final_inventory.rename(columns={'Varenummer': 'SKU', 'Mængde': 'Inventory ULTIMO'}, inplace=True)\n",
    "\n",
    "# # Split data to DK and DE for merging with previous rapport files\n",
    "# INVENTORY_DK = final_inventory[final_inventory['Område'] == 'DK']\n",
    "# INVENTORY_DE = final_inventory[final_inventory['Område'] == 'DE']\n",
    "# INVENTORY_DK = INVENTORY_DK[['SKU', 'Inventory ULTIMO']]\n",
    "# INVENTORY_DE = INVENTORY_DE[['SKU', 'Inventory ULTIMO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a5611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Number           199\n",
      "Warehouse Location    199\n",
      "Quantity              199\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## REVISED SCRIPT - Inventory DK\n",
    "inventory_dk = pd.read_excel(r\"C:\\Users\\Red & White ASUS\\Documents\\(ITA) Data Cleanup and Transformation\\Raw Data - 1st Oct 2025\\DK-END OF MONTH INVENTORY REPORT (Stilling) - September.xlsx\", skiprows=1, usecols=\"A:F\") \n",
    "\n",
    "# Filter columns that are needed for the report\n",
    "inventory_dk['Warehouse Location'] = 'DK'\n",
    "inventory_dk.rename(columns={'Item number' : 'Item Number'}, inplace = True)\n",
    "\n",
    "# Remove '#FP' from the inventory report\n",
    "inventory_dk['Item Number'] = inventory_dk['Item Number'].str.replace('#FP', '', regex=False)\n",
    "\n",
    "inventory_dk_grouped = inventory_dk.groupby(['Item Number', 'Warehouse Location'], as_index=False)['Quantity'].sum()\n",
    "\n",
    "print(inventory_dk_grouped.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72700c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item Number</th>\n",
       "      <th>Warehouse Location</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39473090-DE</td>\n",
       "      <td>DE</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A920Pro-2AW-RE6-20EU</td>\n",
       "      <td>DE</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cposx5-DE</td>\n",
       "      <td>DE</td>\n",
       "      <td>1478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ether10m</td>\n",
       "      <td>DE</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ether7,5m</td>\n",
       "      <td>DE</td>\n",
       "      <td>6065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Item Number Warehouse Location  Quantity\n",
       "0           39473090-DE                 DE         5\n",
       "1  A920Pro-2AW-RE6-20EU                 DE      5100\n",
       "2             Cposx5-DE                 DE      1478\n",
       "3              Ether10m                 DE      5000\n",
       "4             Ether7,5m                 DE      6065"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## REVISED SCRIPT - Inventory DE\n",
    "inventory_de['Warehouse Location'] = np.where(inventory_de['Warehouse Location'].isin(['S2', 'S4']), 'DK', np.where(inventory_de['Warehouse Location'] == 'F1', 'DE', inventory_de['Warehouse Location']))\n",
    "inventory_de= inventory_de[inventory_de['Warehouse Location'] == 'DE']\n",
    "\n",
    "inventory_de['Item Number'] = inventory_de['Item Number'].str.replace('#FP', '', regex=False)\n",
    "inventory_de_grouped = inventory_de.groupby(['Item Number', 'Warehouse Location'], as_index=False)['Quantity'].sum()\n",
    "inventory_de_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02513243",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REVISED - Merge both inventory dataframes and establish the variable Inventroy Ultimo\n",
    "final_inventory = pd.concat([inventory_dk_grouped, inventory_de_grouped], ignore_index=True)\n",
    "final_inventory = final_inventory.groupby(['Item Number', 'Warehouse Location'], as_index=False)['Quantity'].sum()\n",
    "final_inventory.head()\n",
    "\n",
    "# Rename columns for merging purposes\n",
    "final_inventory.rename(columns={'Quantity': 'Inventory ULTIMO'}, inplace=True)\n",
    "\n",
    "# Split data to DK and DE for merging with previous rapport files\n",
    "INVENTORY_DK = final_inventory[final_inventory['Warehouse Location'] == 'DK']\n",
    "INVENTORY_DE = final_inventory[final_inventory['Warehouse Location'] == 'DE']\n",
    "INVENTORY_DK = INVENTORY_DK[['Item Number', 'Inventory ULTIMO']]\n",
    "INVENTORY_DK.rename(columns={'Item Number': 'SKU'}, inplace=True)\n",
    "INVENTORY_DE = INVENTORY_DE[['Item Number', 'Inventory ULTIMO']]\n",
    "INVENTORY_DE.rename(columns={'Item Number': 'SKU'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc9ac39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with '#FP': 0\n",
      "Rows with '#FP': 0\n"
     ]
    }
   ],
   "source": [
    "# Assume your DataFrame is called df and the relevant column is 'Product Code'\n",
    "fp_countdk = INVENTORY_DK['SKU'].str.contains('#FP', na=False).sum()\n",
    "fp_countde = INVENTORY_DE['SKU'].str.contains('#FP', na=False).sum()\n",
    "\n",
    "print(\"Rows with '#FP':\", fp_countdk)\n",
    "print(\"Rows with '#FP':\", fp_countde)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40027419",
   "metadata": {},
   "source": [
    "Data Transformation - Aggregations: Ultimo and Primo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012340bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>Inventory ULTIMO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>###-2XL-B</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>###-2XL-W</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>###-L-B</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>###-L-W</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>###-M-B</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SKU  Inventory ULTIMO\n",
       "0  ###-2XL-B                 6\n",
       "1  ###-2XL-W                 8\n",
       "2    ###-L-B                14\n",
       "3    ###-L-W                 4\n",
       "4    ###-M-B                11"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## REVISED - Creating the two new variables: Previous Month Ultimo and Current Primo\n",
    "# Remove \"#FP\" from SKU in July Rapport files\n",
    "previous_rapport_DK['SKU'] = previous_rapport_DK['SKU'].str.replace('#FP', '', regex=False)\n",
    "previous_rapport_DE['SKU'] = previous_rapport_DE['SKU'].str.replace('#FP', '', regex=False)\n",
    "previous_rapport_TOT['SKU'] = previous_rapport_TOT['SKU'].str.replace('#FP', '', regex=False)\n",
    "\n",
    "# Extract the Current DK Primo using the previous month's \"Inventroy ULTIMO\"\n",
    "ULTIMO_DK = previous_rapport_DK.groupby('SKU', as_index=False)['Inventory ULTIMO'].sum()\n",
    "\n",
    "# Extract the Current DE Primo using the previous month's \"Inventroy ULTIMO\"\n",
    "ULTIMO_DE = previous_rapport_DE.groupby('SKU', as_index=False)['Inventory ULTIMO'].sum()\n",
    "\n",
    "# Extract the Current TOT Primo using the previous month's \"Inventroy ULTIMO\"\n",
    "ULTIMO_TOT = previous_rapport_TOT.groupby('SKU', as_index=False)['Inventory ULTIMO'].sum()\n",
    "ULTIMO_TOT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REVISED - Reorganize DK Ultimo and Primo variables\n",
    "# Rename ULTIMO_DK to Previous Month Primo\n",
    "ULTIMO_DK.rename(columns={'Inventory ULTIMO': 'Previous Month Ultimo'}, inplace=True)\n",
    "\n",
    "# Create new column 'Warehouse Location' and set its value to 'DK'\n",
    "ULTIMO_DK['Warehouse Location'] = 'DK'\n",
    "\n",
    "# Create new column 'Current Month Primo' and set its value to the same as 'Previous Month Ultimo'\n",
    "ULTIMO_DK['Current Month Primo'] = ULTIMO_DK['Previous Month Ultimo']\n",
    "\n",
    "# Reorder columns to have 'SKU', 'Warehouse Location', 'Previous Month Primo', 'Current Month Primo'\n",
    "ULTIMO_DK = ULTIMO_DK[['SKU', 'Warehouse Location', 'Previous Month Ultimo', 'Current Month Primo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3d0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REVISED - Reorganize DE Ultimo and Primo variables\n",
    "# Rename ULTIMO_DE to Previous Month Primo\n",
    "ULTIMO_DE.rename(columns={'Inventory ULTIMO': 'Previous Month Ultimo'}, inplace=True)\n",
    "\n",
    "# Create new column 'Område' and set its value to 'DE'\n",
    "ULTIMO_DE['Warehouse Location'] = 'DE'\n",
    "\n",
    "# Create new column 'Current Month Primo' and set its value to the same as 'Previous Month Primo'\n",
    "ULTIMO_DE['Current Month Primo'] = ULTIMO_DE['Previous Month Ultimo']\n",
    "\n",
    "# Reorder columns to have 'SKU', 'Område', 'Previous Month Primo', 'Current Month Primo'\n",
    "ULTIMO_DE = ULTIMO_DE[['SKU', 'Warehouse Location', 'Previous Month Ultimo', 'Current Month Primo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbae28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>Previous Month Ultimo</th>\n",
       "      <th>Current Month Primo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>###-2XL-B</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>###-2XL-W</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>###-L-B</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>###-L-W</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>###-M-B</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SKU  Previous Month Ultimo  Current Month Primo\n",
       "0  ###-2XL-B                   10.0                 10.0\n",
       "1  ###-2XL-W                    8.0                  8.0\n",
       "2    ###-L-B                   19.0                 19.0\n",
       "3    ###-L-W                   19.0                 19.0\n",
       "4    ###-M-B                   20.0                 20.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## REVISED - Create 'TOT Ultimo' by adding DK and DE 'Previous Month Ultimo' and 'Current Month Primo' based on SKU\n",
    "ULTIMO_TOT = pd.merge(ULTIMO_DK, ULTIMO_DE, on='SKU', how='outer', suffixes=('_DK', '_DE'))\n",
    "ULTIMO_TOT['Previous Month Ultimo'] = ULTIMO_TOT['Previous Month Ultimo_DK'].fillna(0) + ULTIMO_TOT['Previous Month Ultimo_DE'].fillna(0)\n",
    "ULTIMO_TOT['Current Month Primo'] = ULTIMO_TOT['Current Month Primo_DK'].fillna(0) + ULTIMO_TOT['Current Month Primo_DE'].fillna(0)\n",
    "ULTIMO_TOT = ULTIMO_TOT[['SKU', 'Previous Month Ultimo', 'Current Month Primo']]\n",
    "ULTIMO_TOT.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f8041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item Number</th>\n",
       "      <th>Quantity Received</th>\n",
       "      <th>Created At</th>\n",
       "      <th>Order Number</th>\n",
       "      <th>Closed Time</th>\n",
       "      <th>Warehouse Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VL308.096</td>\n",
       "      <td>216</td>\n",
       "      <td>2025-09-30 12:31:17.019</td>\n",
       "      <td>FLA-000118</td>\n",
       "      <td>2025-09-30 12:31:51.660</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VL305.741</td>\n",
       "      <td>501</td>\n",
       "      <td>2025-09-30 12:31:17.019</td>\n",
       "      <td>FLA-000118</td>\n",
       "      <td>2025-09-30 12:31:51.660</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Terminal stand White</td>\n",
       "      <td>4000</td>\n",
       "      <td>2025-09-30 11:44:17.150</td>\n",
       "      <td>FLA-000117</td>\n",
       "      <td>2025-09-30 11:44:58.565</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>###-S-W</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-09-30 10:55:53.046</td>\n",
       "      <td>FR-Tøj-modtagelse-(30/09)</td>\n",
       "      <td>2025-09-30 11:33:03.682</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>###-M-W</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-09-30 10:55:53.046</td>\n",
       "      <td>FR-Tøj-modtagelse-(30/09)</td>\n",
       "      <td>2025-09-30 11:33:03.682</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Item Number  Quantity Received              Created At  \\\n",
       "1             VL308.096                216 2025-09-30 12:31:17.019   \n",
       "2             VL305.741                501 2025-09-30 12:31:17.019   \n",
       "3  Terminal stand White               4000 2025-09-30 11:44:17.150   \n",
       "4               ###-S-W                 10 2025-09-30 10:55:53.046   \n",
       "5               ###-M-W                 20 2025-09-30 10:55:53.046   \n",
       "\n",
       "                Order Number             Closed Time  Warehouse Id  \n",
       "1                 FLA-000118 2025-09-30 12:31:51.660           706  \n",
       "2                 FLA-000118 2025-09-30 12:31:51.660           706  \n",
       "3                 FLA-000117 2025-09-30 11:44:58.565           706  \n",
       "4  FR-Tøj-modtagelse-(30/09) 2025-09-30 11:33:03.682           653  \n",
       "5  FR-Tøj-modtagelse-(30/09) 2025-09-30 11:33:03.682           653  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbound.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a55765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Red & White ASUS\\AppData\\Local\\Temp\\ipykernel_3884\\111717795.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  goods_in_DK['Warehouse Location'] = 'DK'\n",
      "C:\\Users\\Red & White ASUS\\AppData\\Local\\Temp\\ipykernel_3884\\111717795.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  goods_in_DE['Warehouse Location'] = 'DE'\n"
     ]
    }
   ],
   "source": [
    "## REVISED - Creating new variable: Goods In\n",
    "# Cleanup SKU by removing \"#FP\"\n",
    "inbound['Item Number'] = inbound['Item Number'].str.replace('#FP', '', regex=False)\n",
    "\n",
    "# Rename all columns from Danish to English \n",
    "inbound = inbound.rename(columns={'Varenummer' : 'Item Number',\n",
    "                        'Mængde modtaget' : 'Quantity Received',\n",
    "                        'Oprettet' : 'Created At',\n",
    "                        'Lukkettidspunkt' : 'Closed Time',\n",
    "                        'Lagerid' : 'Warehouse Id'\n",
    "})\n",
    "\n",
    "# Filter for rows where 'Item Number' does not contain '-C-' or '-R-'\n",
    "inbound = inbound[~inbound['Item Number'].str.contains('-C-|-R-', na=False)]\n",
    "\n",
    "# Create 'Goods in' by aggregating the total Quantity per Varenummer and Område filtering by 'DK' only\n",
    "goods_in_DK = inbound[inbound['Warehouse Id'] == 653]\n",
    "goods_in_DK['Warehouse Location'] = 'DK'\n",
    "goods_in_DK_grouped = goods_in_DK.groupby(['Item Number', 'Warehouse Location'], as_index=False)['Quantity Received'].sum()\n",
    "goods_in_DK_grouped.rename(columns={'Item Number': 'SKU', 'Quantity Received': 'Goods In'}, inplace=True)\n",
    "goods_in_DK_grouped = goods_in_DK_grouped[['SKU', 'Goods In']]\n",
    "\n",
    "# Create 'Goods in' by aggregating the total Mængde modtaget per Varenummer and Område filtering by 'DE' only\n",
    "goods_in_DE = inbound[inbound['Warehouse Id'] == 706]\n",
    "goods_in_DE['Warehouse Location'] = 'DE'\n",
    "goods_in_DE_grouped = goods_in_DE.groupby(['Item Number', 'Warehouse Location'], as_index=False)['Quantity Received'].sum()\n",
    "goods_in_DE_grouped.rename(columns={'Item Number': 'SKU', 'Quantity Received': 'Goods In'}, inplace=True)\n",
    "goods_in_DE_grouped = goods_in_DE_grouped[['SKU', 'Goods In']]\n",
    "\n",
    "# Create 'Goods in' by aggregating the total Mængde modtaget per Varenummer and Område by adding DK and DE values to get 'TOT'\n",
    "goods_in_TOT = pd.merge(goods_in_DK_grouped, goods_in_DE_grouped, on='SKU', how='outer', suffixes=('_DK', '_DE'))\n",
    "goods_in_TOT['Goods In'] = goods_in_TOT['Goods In_DK'].fillna(0) + goods_in_TOT['Goods In_DE'].fillna(0)\n",
    "goods_in_TOT = goods_in_TOT[['SKU', 'Goods In']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating new variable: Moved to Production (Negative Values)\n",
    "# Filter according to proper Shipping Address\n",
    "production = production[production['ShippingAddress_CustomerName'] == 'Production Order']\n",
    "production.rename(columns={'ItemNumber':'Item Number'}, inplace=True)\n",
    "\n",
    "# Cleanup SKU by removeing \"#FP\"\n",
    "production['Item Number'] = production['Item Number'].str.replace('#FP', '', regex=False)\n",
    "\n",
    "# Create 'Moved to Production' by aggregating the total Quantity Produced per SKU filtering SourceCountry by 'DK' only\n",
    "production_DK = production[production['PickingWarehouseCountry'] == 'DK']\n",
    "moved_to_production_DK = production_DK.groupby(['Item Number','PickingWarehouseCountry'], as_index=False)['QuantityPacked'].sum()\n",
    "moved_to_production_DK.rename(columns={'QuantityPacked': 'Moved to Production'}, inplace=True)\n",
    "moved_to_production_DK = moved_to_production_DK[['Item Number', 'Moved to Production', 'PickingWarehouseCountry']]\n",
    "moved_to_production_DK['Moved to Production'] = moved_to_production_DK['Moved to Production'] * -1\n",
    "\n",
    "# Create 'Moved to Production' by aggregating the total Quantity Produced per SKU filtering SourceCountry by 'DE' only\n",
    "production_DE = production[production['PickingWarehouseCountry'] == 'DE']\n",
    "moved_to_production_DE = production_DE.groupby(['Item Number','PickingWarehouseCountry'], as_index=False)['QuantityPacked'].sum()\n",
    "moved_to_production_DE.rename(columns={'QuantityPacked': 'Moved to Production'}, inplace=True)\n",
    "moved_to_production_DE = moved_to_production_DE[['Item Number', 'Moved to Production', 'PickingWarehouseCountry']]\n",
    "moved_to_production_DE['Moved to Production'] = moved_to_production_DE['Moved to Production'] * -1\n",
    "\n",
    "# Create 'Moved to Production' by aggregating the total Quantity Produced per SKU by combining DK and DE values to get 'TOT'\n",
    "moved_to_production_TOT = pd.merge(moved_to_production_DK, moved_to_production_DE, on='Item Number', how='outer', suffixes=('_DK', '_DE'))\n",
    "moved_to_production_TOT['Moved to Production'] = moved_to_production_TOT['Moved to Production_DK'].fillna(0) + moved_to_production_TOT['Moved to Production_DE'].fillna(0)\n",
    "moved_to_production_TOT.rename(columns={'PickingWarehouseCountry_DK' : 'DK', 'PickingWarehouseCountry_DE' : 'DE'}, inplace = True)\n",
    "moved_to_production_TOT = moved_to_production_TOT[['Item Number', 'Moved to Production', 'DK', 'DE']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e10f9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>Inbound from Production</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39473090-C-DK</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A920Pro-2AW-RE6-20EU-C-AM</td>\n",
       "      <td>3400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A920Pro-2AW-RE6-20EU-C-FR</td>\n",
       "      <td>6600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A920Pro-2AW-RE6-20EU-C-UK</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cposx5-C-DE</td>\n",
       "      <td>860.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         SKU  Inbound from Production\n",
       "0              39473090-C-DK                    420.0\n",
       "1  A920Pro-2AW-RE6-20EU-C-AM                   3400.0\n",
       "2  A920Pro-2AW-RE6-20EU-C-FR                   6600.0\n",
       "3  A920Pro-2AW-RE6-20EU-C-UK                    200.0\n",
       "4                Cposx5-C-DE                    860.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating new variable: Inbound from Production\n",
    "# Rename columns from Danish to English \n",
    "inbound_prod = inbound_prod.rename(columns={'Varenummer' : 'Item Number',\n",
    "                                            'Mængde modtaget' : 'Quantity Received',\n",
    "                                            'Oprettet' : 'Created At',\n",
    "                                            'Lukkettidspunkt' : 'Closed Time',\n",
    "                                            'Lagerid' : 'Warehouse Id'\n",
    "})\n",
    "\n",
    "# Filter for rows where 'Item Number' contains '-C-' or '-R-'\n",
    "inbound_prod = inbound_prod[inbound_prod['Item Number'].str.contains('-C-|-R-', na=False)]\n",
    "\n",
    "# Cleanup SKU by removing \"#FP\"\n",
    "inbound_prod['Item Number'] = inbound_prod['Item Number'].str.replace('#FP', '', regex=False)\n",
    "\n",
    "# Define a function to apply the label based on 'Warehouse ID'\n",
    "def label_warehouse(warehouse_id):\n",
    "    if warehouse_id == 653:\n",
    "        return 'DK'\n",
    "    elif warehouse_id == 706:\n",
    "        return 'DE'\n",
    "    else:\n",
    "        return 'Other'\n",
    "    \n",
    "# Apply the function to the 'Warehouse ID' column\n",
    "inbound_prod['Warehouse Location'] = inbound_prod['Warehouse Id'].apply(label_warehouse)\n",
    "\n",
    "# Create 'Inbound from Production' by aggregating the total Quantity per Item Number and Warehouse Location filtering by 'DK' only\n",
    "inbound_prod_DK = inbound_prod[inbound_prod['Warehouse Location'] == 'DK']\n",
    "inbound_prod_DK_grouped = inbound_prod_DK.groupby(['Item Number', 'Warehouse Location'], as_index=False)['Quantity Received'].sum()\n",
    "inbound_prod_DK_grouped.rename(columns={'Item Number': 'SKU', 'Quantity Received': 'Inbound from Production'}, inplace=True)\n",
    "inbound_prod_DK_grouped = inbound_prod_DK_grouped[['SKU', 'Inbound from Production', 'Warehouse Location']]\n",
    "\n",
    "# Create 'Inbound from Production' by aggregating the total Quantity per Item Number and Warehouse Location filtering by 'DE' only\n",
    "inbound_prod_DE = inbound_prod[inbound_prod['Warehouse Location'] == 'DE']\n",
    "inbound_prod_DE_grouped = inbound_prod_DE.groupby(['Item Number', 'Warehouse Location'], as_index=False)['Quantity Received'].sum()\n",
    "inbound_prod_DE_grouped.rename(columns={'Item Number': 'SKU', 'Quantity Received': 'Inbound from Production'}, inplace=True)\n",
    "inbound_prod_DE_grouped = inbound_prod_DE_grouped[['SKU', 'Inbound from Production', 'Warehouse Location']]\n",
    "\n",
    "# Create 'Inbound from Production' by aggregating the total Mængde modtaget per Varenummer and Område by adding DK and DE values to get 'TOT'\n",
    "inbound_prod_TOT = pd.merge(inbound_prod_DK_grouped, inbound_prod_DE_grouped, on='SKU', how='outer', suffixes=('_DK', '_DE'))\n",
    "inbound_prod_TOT['Inbound from Production'] = inbound_prod_TOT['Inbound from Production_DK'].fillna(0) + inbound_prod_TOT['Inbound from Production_DE'].fillna(0)\n",
    "inbound_prod_TOT = inbound_prod_TOT[['SKU', 'Inbound from Production']]\n",
    "\n",
    "inbound_prod_TOT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ddba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>Shipments Out</th>\n",
       "      <th>PickingWarehouseCountry_DK</th>\n",
       "      <th>PickingWarehouseCountry_DE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>###-L-B</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>###-L-W</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>###-M-W</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>###-S-B</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>###-S-W</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>DK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SKU  Shipments Out PickingWarehouseCountry_DK  \\\n",
       "0  ###-L-B          -14.0                         DK   \n",
       "1  ###-L-W           -4.0                         DK   \n",
       "2  ###-M-W           -1.0                         DK   \n",
       "3  ###-S-B           -8.0                         DK   \n",
       "4  ###-S-W           -3.0                         DK   \n",
       "\n",
       "  PickingWarehouseCountry_DE  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                        NaN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating new variable: Shipments Out (Negative Values)\n",
    "# Cleanup SKU by removeing \"#FP\"\n",
    "shipments['ItemNumber'] = shipments['ItemNumber'].str.replace('#FP', '', regex=False)\n",
    "\n",
    "# Create 'Shipments Out' by aggregating the total Quantity Shipped per SKU filtering SourceCountry by 'DK' only\n",
    "shipments_DK = shipments[shipments['PickingWarehouseCountry'] == 'DK']\n",
    "shipments_DK_grouped = shipments_DK.groupby(['ItemNumber', 'PickingWarehouseCountry'], as_index=False)['QuantityPacked'].sum()\n",
    "shipments_DK_grouped.rename(columns={'ItemNumber': 'SKU', 'QuantityPacked': 'Shipments Out'}, inplace=True)\n",
    "shipments_DK_grouped = shipments_DK_grouped[['SKU', 'Shipments Out', 'PickingWarehouseCountry']]\n",
    "shipments_DK_grouped['Shipments Out'] = shipments_DK_grouped['Shipments Out'] * -1\n",
    "\n",
    "shipments_DK_grouped.rename(columns={'ItemNumber': 'SKU'}, inplace=True)\n",
    "\n",
    "# Create 'Shipments Out' by aggregating the total Quantity Shipped per SKU filtering SourceCountry by 'DE' only\n",
    "shipments_DE = shipments[shipments['PickingWarehouseCountry'] == 'DE']\n",
    "shipments_DE_grouped = shipments_DE.groupby(['ItemNumber', 'PickingWarehouseCountry'], as_index=False)['QuantityPacked'].sum()\n",
    "shipments_DE_grouped.rename(columns={'ItemNumber': 'SKU', 'QuantityPacked': 'Shipments Out'}, inplace=True)\n",
    "shipments_DE_grouped = shipments_DE_grouped[['SKU', 'Shipments Out', 'PickingWarehouseCountry']]\n",
    "shipments_DE_grouped['Shipments Out'] = shipments_DE_grouped['Shipments Out'] * -1\n",
    "\n",
    "shipments_DE_grouped.rename(columns={'ItemNumber': 'SKU'}, inplace=True)\n",
    "\n",
    "# Create 'Shipments Out' by aggregating the total Quantity Shipped per SKU by combining DK and DE values to get 'TOT'\n",
    "shipments_TOT = pd.merge(shipments_DK_grouped, shipments_DE_grouped, on='SKU', how='outer', suffixes=('_DK', '_DE'))\n",
    "shipments_TOT['Shipments Out'] = shipments_TOT['Shipments Out_DK'].fillna(0) + shipments_TOT['Shipments Out_DE'].fillna(0)\n",
    "shipments_TOT = shipments_TOT[['SKU', 'Shipments Out', 'PickingWarehouseCountry_DK', 'PickingWarehouseCountry_DE']]\n",
    "\n",
    "shipments_TOT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9990fde3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Previous Month Ultimo', 'Current Month Primo'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m merged_DK \u001b[38;5;241m=\u001b[39m merged_DK\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m## Creating the DE Rapport\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Merge all dataframes into a single dataframe based on SKU filtering by DE only\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m merged_DE \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\u001b[43mULTIMO_DE\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSKU\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrevious Month Ultimo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCurrent Month Primo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m, INVENTORY_DE, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSKU\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m merged_DE \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(merged_DE, goods_in_DE_grouped[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSKU\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGoods In\u001b[39m\u001b[38;5;124m'\u001b[39m]], on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSKU\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m merged_DE \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(merged_DE, moved_to_production_DE[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mItem Number\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMoved to Production\u001b[39m\u001b[38;5;124m'\u001b[39m]], left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSKU\u001b[39m\u001b[38;5;124m'\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mItem Number\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Red & White ASUS\\.conda\\envs\\cleanenv\\lib\\site-packages\\pandas\\core\\frame.py:4119\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4118\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4119\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4121\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Red & White ASUS\\.conda\\envs\\cleanenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6210\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6214\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6216\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Red & White ASUS\\.conda\\envs\\cleanenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6263\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6264\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Previous Month Ultimo', 'Current Month Primo'] not in index\""
     ]
    }
   ],
   "source": [
    "## Creating the variable: Variants and Combining all Sheets according to location: DK, DE and TOT\n",
    "# Create variants by subtracting Inventory Ultimo by the SUM of all combined Current Month Primo, Goods In, Moved to Production, Inbound from Production, Shipments Out\n",
    "\n",
    "## Creating the DK Rapport\n",
    "# Merge all dataframes into a single dataframe based on SKU filtering by DK only\n",
    "merged_DK = pd.merge(ULTIMO_DK[['SKU', 'Previous Month Ultimo', 'Current Month Primo']], INVENTORY_DK, on='SKU', how='outer')\n",
    "merged_DK = pd.merge(merged_DK, goods_in_DK_grouped[['SKU', 'Goods In']], on='SKU', how='outer')\n",
    "merged_DK = pd.merge(merged_DK, moved_to_production_DK[['Item Number', 'Moved to Production']], left_on='SKU', right_on='Item Number', how='outer')\n",
    "merged_DK = pd.merge(merged_DK, inbound_prod_DK_grouped[['SKU', 'Inbound from Production']], on='SKU', how='outer')\n",
    "merged_DK = pd.merge(merged_DK, shipments_DK_grouped[['SKU', 'Shipments Out']], on='SKU', how='outer')\n",
    "merged_DK['Variants'] = merged_DK['Inventory ULTIMO'].fillna(0) - (merged_DK['Current Month Primo'].fillna(0) + \n",
    "                                                                   merged_DK['Goods In'].fillna(0) + \n",
    "                                                                   merged_DK['Moved to Production'].fillna(0) + \n",
    "                                                                   merged_DK['Inbound from Production'].fillna(0) + \n",
    "                                                                   merged_DK['Shipments Out'].fillna(0))\n",
    "\n",
    "merged_DK = merged_DK[['SKU', 'Previous Month Ultimo', 'Current Month Primo', 'Goods In', 'Moved to Production', 'Inbound from Production', 'Shipments Out', 'Variants', 'Inventory ULTIMO']]\n",
    "merged_DK = merged_DK.fillna(0)\n",
    "\n",
    "## Creating the DE Rapport\n",
    "# Merge all dataframes into a single dataframe based on SKU filtering by DE only\n",
    "merged_DE = pd.merge(ULTIMO_DE[['SKU', 'Previous Month Ultimo', 'Current Month Primo']], INVENTORY_DE, on='SKU', how='outer')\n",
    "merged_DE = pd.merge(merged_DE, goods_in_DE_grouped[['SKU', 'Goods In']], on='SKU', how='outer')\n",
    "merged_DE = pd.merge(merged_DE, moved_to_production_DE[['Item Number', 'Moved to Production']], left_on='SKU', right_on='Item Number', how='outer')\n",
    "merged_DE = pd.merge(merged_DE, inbound_prod_DE_grouped[['SKU', 'Inbound from Production']], on='SKU', how='outer')\n",
    "merged_DE = pd.merge(merged_DE, shipments_DE_grouped[['SKU', 'Shipments Out']], on='SKU', how='outer')\n",
    "merged_DE['Variants'] = merged_DE['Inventory ULTIMO'].fillna(0) - (merged_DE['Current Month Primo'].fillna(0) + \n",
    "                                                                   merged_DE['Goods In'].fillna(0) +\n",
    "                                                                    merged_DE['Moved to Production'].fillna(0) +\n",
    "                                                                     merged_DE['Inbound from Production'].fillna(0) +\n",
    "                                                                        merged_DE['Shipments Out'].fillna(0))\n",
    "\n",
    "merged_DE = merged_DE[['SKU', 'Previous Month Ultimo', 'Current Month Primo', 'Goods In', 'Moved to Production', 'Inbound from Production', 'Shipments Out', 'Variants', 'Inventory ULTIMO']]\n",
    "merged_DE = merged_DE.fillna(0)\n",
    "\n",
    "## Create a 'TOT' sheet by merging both DK and DE sheets based on SKU\n",
    "# Combine DK and DE into TOT\n",
    "merged_TOT = pd.concat([merged_DK, merged_DE], ignore_index=True)\n",
    "merged_TOT = merged_TOT.fillna(0)\n",
    "\n",
    "# Group by SKU and sum all numeric columns\n",
    "merged_TOT = merged_TOT.groupby('SKU', as_index=False).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine all rapports into a single Excel file with multiple sheets\n",
    "# Replace Path file to desired location\n",
    "with pd.ExcelWriter(r\"C:\\Users\\Red & White ASUS\\Documents\\(ITA) Data Cleanup and Transformation\\Raw Data\\Final Rapport Sep 2025.xlsx\", engine='openpyxl') as writer:\n",
    "    merged_DK.to_excel(writer, sheet_name='DK', index=False)\n",
    "    merged_DE.to_excel(writer, sheet_name='DE', index=False)\n",
    "    merged_TOT.to_excel(writer, sheet_name='Total', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa62521b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
